{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projet :  Détection d'activité humaine - DTW et classification avec réduction de dimension\n",
    "\n",
    "Dans ce projet, nous essaierons de prédire l'activité humaine (1-Marche, 2-Monter, 3-Descendre, 4-Assis, 5-Debout ou 6-Couché) en utilisant les capteurs du smartphone. C'est-à-dire qu'en utilisant les méthodes suivantes, le smartphone peut détecter ce que nous faisons en ce moment.\n",
    "\n",
    "\n",
    "En utilisant l'accéléromètre et le gyroscope intégrés dans le smartphone,  l'accélération linéaire 3-axes et la vitesse angulaire 3-axes à un taux constant de 50Hz ont été relevées. Les expériences ont été enregistrées sur vidéo pour étiqueter les données manuellement. L'ensemble de données obtenu a été divisé de façon aléatoire en deux ensembles, où 70 % des volontaires ont été sélectionnés pour générer les données d'entraînement et 30 % les données d'essai.\n",
    "\n",
    "<img src=\"files/HARDataset.JPG\" width=\"800\" height=\"600\"  >\n",
    "\n",
    "Il est fourni pour chaque enregistrement de l'ensemble de données : \n",
    "- L'accélération triaxiale de l'accéléromètre (accélération totale) et l'accélération estimée du corps. \n",
    "- Vitesse angulaire triaxiale du gyroscope. \n",
    "- Son étiquette d'activité. \n",
    "- Un identifiant du sujet qui a réalisé l'expérience.\n",
    "\n",
    "\n",
    "Ces séances se décomposent en 3 parties : \n",
    "- Partie I : DTW et application du TD\n",
    "- Partie II : Système de reconnaissance d'activité physique avec la DTW\n",
    "- Partie III : Comparaison de la programmation dynamique avec une méthode de classification après prétraitement des données par ACP\n",
    "\n",
    "\n",
    "**Dataset et description :**\n",
    "https://archive.ics.uci.edu/ml/datasets/Human+Activity+Recognition+Using+Smartphones\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import math\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "COLUMN_NAMES = [\n",
    "    'user',\n",
    "    'activity',\n",
    "    'timestamp',\n",
    "    'x-axis',\n",
    "    'y-axis',\n",
    "    'z-axis'\n",
    "]\n",
    "\n",
    "LABELS = [\n",
    "    'Downstairs',\n",
    "    'Jogging',\n",
    "    'Sitting',\n",
    "    'Standing',\n",
    "    'Upstairs',\n",
    "    'Walking'\n",
    "]\n",
    "\n",
    "DATA_PATH = 'data/WISDM_ar_v1.1_raw.txt'\n",
    "\n",
    "RANDOM_SEED = 13\n",
    "\n",
    "# Data preprocessing\n",
    "TIME_STEP = 100\n",
    "\n",
    "# Model\n",
    "N_CLASSES = 6\n",
    "N_FEATURES = 3  # x-acceleration, y-acceleration, z-acceleration\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Chargement des données d'apprentissage et de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-5-fff44b7bccbb>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-5-fff44b7bccbb>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    data = pd.read_csv(DATA_PATH, header=None, names=COLUMN_NAMES)\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "# LOAD DATA\n",
    "data = pd.read_csv(DATA_PATH, header=None, names=COLUMN_NAMES)\n",
    "data['z-axis'].replace({';': ''}, regex=True, inplace=True)\n",
    "data = data.dropna()\n",
    "\n",
    "# SHOW GRAPH FOR JOGGING\n",
    "data[data['activity'] == 'Jogging'][['x-axis']][:50].plot(subplots=True, figsize=(16, 12), title='Jogging')\n",
    "    plt.xlabel('Timestep')\n",
    "    plt.ylabel('X acceleration (dg)')\n",
    "\n",
    "    # SHOW ACTIVITY GRAPH\n",
    "    activity_type = data['activity'].value_counts().plot(kind='bar', title='Activity type')\n",
    "    #plt.show()\n",
    "\n",
    "    # DATA PREPROCESSING\n",
    "    data_convoluted = []\n",
    "    labels = []\n",
    "\n",
    "    # Slide a \"SEGMENT_TIME_SIZE\" wide window with a step size of \"TIME_STEP\"\n",
    "    for i in range(0, len(data) - SEGMENT_TIME_SIZE, TIME_STEP):\n",
    "        x = data['x-axis'].values[i: i + SEGMENT_TIME_SIZE]\n",
    "        y = data['y-axis'].values[i: i + SEGMENT_TIME_SIZE]\n",
    "        z = data['z-axis'].values[i: i + SEGMENT_TIME_SIZE]\n",
    "        data_convoluted.append([x, y, z])\n",
    "\n",
    "        # Label for a data window is the label that appears most commonly\n",
    "        label = stats.mode(data['activity'][i: i + SEGMENT_TIME_SIZE])[0][0]\n",
    "        labels.append(label)\n",
    "\n",
    "    # Convert to numpy\n",
    "    data_convoluted = np.asarray(data_convoluted, dtype=np.float32).transpose(0, 2, 1)\n",
    "\n",
    "    # One-hot encoding\n",
    "    labels = np.asarray(pd.get_dummies(labels), dtype=np.float32)\n",
    "    print(\"Convoluted data shape: \", data_convoluted.shape)\n",
    "    print(\"Labels shape:\", labels.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partie I : Implémentation de l'algorithme de programmation dynamique \n",
    "\n",
    "1. Ecrivez une fonction en python DTW qui implémente le calcul et l'affichage de la matrice des coûts définie en TD. \n",
    "\n",
    "2. Afin d'adapter facilement le calcul des coûts suivant la nature des données (et donc des distances utilisées), écrivez une fonction pour chaque distance (euclidienne, lettres, sons) qui apparaîtra en paramètre de la fonction DTW."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import *\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "def DTW(A, B, window = sys.maxsize, d = lambda x,y: np.linalg.norm(x-y)):\n",
    "    # create the cost matrix\n",
    "    A= np.array(A)\n",
    "    B= np.array(B)\n",
    "    M= len(A)\n",
    "    N= len(B)\n",
    "    cost = np.ones((M, N))\n",
    "\n",
    "    # initialize the first row and column\n",
    "    cost[0, 0] = d(A[0], B[0])\n",
    "    for i in range(1, M):\n",
    "        cost[i, 0] = cost[i-1, 0] + d(A[i], B[0])\n",
    "\n",
    "    for j in range(1, N):\n",
    "        cost[0, j] = cost[0, j-1] + d(A[0], B[j])\n",
    "    # fill in the rest of the matrix\n",
    "    for i in range(1, M):\n",
    "        for j in range(max(1, i - window), min(N, i + window)):\n",
    "            choices = cost[i - 1, j - 1], cost[i, j-1], cost[i-1, j]\n",
    "            cost[i, j] = min(choices) + d(A[i], B[j])\n",
    "\n",
    "    # find the optimal path\n",
    "    n, m = N - 1, M - 1\n",
    "    path = []\n",
    "\n",
    "    while (m, n) != (0, 0):\n",
    "        path.append((m, n))\n",
    "        m, n = min((m - 1, n), (m, n - 1), (m - 1, n - 1), key = lambda x: cost[x[0], x[1]])\n",
    "    \n",
    "    path.append((0,0))\n",
    "    return cost[-1, -1]/(N+M), path\n",
    "\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Application aux exercices \n",
    "\n",
    " Testez vos programmes sur les exercices vus en TD. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Matrice de confusion')\n",
    "cm=confusion_matrix(y_test,predicted_nn_HAR)\n",
    "sns.heatmap(data=cm,fmt='.0f',xticklabels=np.unique(labels),yticklabels=np.unique(labels),annot=True)\n",
    "\n",
    "# score de performance\n",
    "print('Accuracy sur base de test :',accuracy_score(y_test,predicted_nn_HAR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partie II : Comparaison de la programmation dynamique avec une méthode de classification après prétraitement des données\n",
    "\n",
    "Dans cette partie, nous allons comparer les résultats de la DTW avec ceux d'une méthode de classification de données : les k-plus proches voisins.\n",
    "\n",
    "Nous utiliserons les fonctions permettant de calculer l'ACP et les kppv via la librairie python *scikit-learn*.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prétraitement par ACP\n",
    "\n",
    "Pour tester une méthode de classification, il faut d'abord réduire la dimension des MFCC\n",
    "1. Pour chaque enregistrement audio, calculez le vecteur de $R^{13}$ égal à la moyenne sur toutes les fenêtres de\n",
    "MFCC. Ainsi chaque enregistrement sera représenté par un seul vecteur de 13 coefficients MFCC.\n",
    "\n",
    "2. A partir de tous les enregistrements de la base d'apprentissage et en utilisant la fonction *PCA* de la librairie *scikit-learn*, calculez les 3 axes principaux de l'ACP en\n",
    "extrayant les 3 vecteurs propres, notés $X_1$, $X_2$, $X_3$, associés aux 3 plus grandes valeurs propres de la matrice de\n",
    "variance-covariance $\\Sigma_{App}$.Ces vecteurs propres consitueront la nouvelle base de données.\n",
    "\n",
    "3. Projetez les données de la base d'apprentissage et de test dans cette nouvelle base en multipliant chaque\n",
    "vecteur par la base $P = [X_1X_2X_3]$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'BaseApp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-757e0df32e92>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdatasetApp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m13\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseApp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdatasetTest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m13\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseTest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mn_components\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseApp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'BaseApp' is not defined"
     ]
    }
   ],
   "source": [
    "datasetApp=np.zeros((13,len(BaseApp)))\n",
    "datasetTest=np.zeros((13,len(BaseTest)))\n",
    "n_components=2\n",
    "\n",
    "for i in range(len(BaseApp)):\n",
    "    datasetApp[:,i]=np.mean(listBaseApp[i],axis=1)\n",
    "\n",
    "for i in range(len(BaseTest)):\n",
    "    datasetTest[:,i]=np.mean(listBaseTest[i],axis=1)\n",
    "\n",
    "# En implémentant l'ACP \n",
    "cov_mat=np.cov(datasetApp)\n",
    "print(cov_mat.shape)\n",
    "\n",
    "eig_vals, eig_vecs = np.linalg.eig(cov_mat)\n",
    "\n",
    "principalAxes=np.zeros((13,n_components))\n",
    "for i in range(n_components):\n",
    "    principalAxes[:,i]=eig_vecs[:,i]\n",
    "\n",
    "principalComponentsApp = datasetApp.dot(principalAxes)\n",
    "principalComponentsTest = datasetTest.dot(principalAxes)\n",
    "\n",
    "# affichage des points\n",
    "plt.scatter(principalComponentsApp[:, 0], principalComponentsApp[:, 1],marker='^')\n",
    "plt.scatter(principalComponentsTest[:, 0], principalComponentsTest[:, 1],marker='o')\n",
    "plt.title(\"Base d'Apprentissage/Test\")\n",
    "plt.xlabel(\"PC1\")\n",
    "plt.ylabel(\"PC2\");\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Pourcentage d'information conservée\n",
    "Contraste=sum(eig_vals[range(n_components)])/sum(eig_vals)\n",
    "print(\"Contraste :\", Contraste)\n",
    "\n",
    "# En utilisant sklearn    \n",
    "pca = PCA(n_components)\n",
    "principalComponentsApp = pca.fit_transform(np.transpose(datasetApp))\n",
    "principalComponentsTest= pca.transform(np.transpose(datasetTest))\n",
    "\n",
    "# affichage des points\n",
    "#plt.scatter(principalComponentsApp[:, 0], principalComponentsApp[:, 1],marker='^')\n",
    "#plt.scatter(principalComponentsTest[:, 0], principalComponentsTest[:, 1],marker='o')\n",
    "#plt.title(\"Base d'Apprentissage/Test\")\n",
    "#plt.xlabel(\"PC1\")\n",
    "#plt.ylabel(\"PC2\");\n",
    "#plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# Conservation de l'information : Variance \n",
    "print(sum(pca.explained_variance_ratio_))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification par k plus proches voisins\n",
    "\n",
    "En intelligence artificielle, la méthode des k plus proches voisins (k-ppv) est une méthode d'apprentissage\n",
    "supervisé. Dans ce cadre, on dispose d'une base de données d'apprentissage constituée de couples  \"donnée-label\". Pour estimer la sortie associée à une nouvelle entrée x, la méthode des k plus proches voisins consiste à prendre\n",
    "en compte (de façon identique) les k échantillons d'apprentissage dont l'entrée est la plus proche de la nouvelle\n",
    "entrée x, selon une distance à définir. L'algorithme 1 associé et un exemple (figure 1) sont données par la suite.\n",
    "\n",
    "<img src=\"files/AlgoKppv.png\" width=\"900\" height=\"800\"  >\n",
    "\n",
    "<img src=\"files/kppv.png\" width=\"300\" height=\"300\"  >\n",
    "\n",
    "**Exemple de classification par k-ppv.** L'échantillon de test (cercle vert) doit être classé soit dans la première\n",
    "classe des carrés bleus, soit dans la deuxième classe des triangles rouges. \n",
    "Si k = 3 (cercle plein), il est assigné à la deuxième classe parce qu'il y a 2 triangles et seulement 1 carré à l'intérieur du cercle intérieur. \n",
    "Si k = 5 (cercle en pointillés), il est assigné à la première classe (3 carrés contre 2 triangles à l'intérieur du cercle extérieur)\n",
    "\n",
    "\n",
    "1. En utilisant la fonction *KNeighborsClassifier* de la librairie *sklearn.neighbors*, réalisez une classification par k-ppv sur la base d'apprentissage et la base de test que vous avez prédéfinies (prendre $k=1$).\n",
    "\n",
    "2. Evaluez la méthode des k-ppv par le calcul de la matrice de confusion et du taux de reconnaissance.\n",
    "\n",
    "3. Modifiez la valeur de $k$ pour les k-ppv. Améliorez-vous les scores de reconnaissance ?\n",
    "\n",
    "4. Comparez vos résultats avec ceux de la DTW.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'principalComponentsApp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-cb674885a050>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mknn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKNeighborsClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_neighbors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mknn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprincipalComponentsApp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverdictApp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mpred_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mknn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprincipalComponentsTest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'principalComponentsApp' is not defined"
     ]
    }
   ],
   "source": [
    "error=[]\n",
    "verdictApp=np.arange(13)\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=1)\n",
    "knn.fit(principalComponentsApp, verdictApp)\n",
    "pred_i = knn.predict(principalComponentsTest)\n",
    "\n",
    "print(pred_i)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Partie III : comparaison avec d'autres données \n",
    "\n",
    "Il est désormais fourni pour chaque enregistrement de l'ensemble de données en plus de l'accélération triaxiale de l'accéléromètre et de la vitesse angulaire triaxiale du gyroscope: \n",
    "- Un vecteur de 561 caractéristiques avec des variables dans le domaine du temps et de la fréquence. \n",
    "- Son étiquette d'activité. \n",
    "- Un identifiant du sujet qui a réalisé l'expérience.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
